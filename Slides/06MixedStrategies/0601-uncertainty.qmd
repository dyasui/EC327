
<!-- ## Double or Nothing 'game'

![](figures/doubleornothing.png)

---

## Expected Payoff Examples

Zoidberg's expected payout if he Lets it Ride is 
$0.50(\$10) + 0.50(\$0) = \$5 - \$0 = \$5$.

::: {.incremental}
  * Let's face it, Zoidberg always has luck stacked against him, so suppose instead the coin has a 75\% probability of tails,

  * The expected payoff would then be 
  $$0.25(\$10) + 0.75(\$0) = \$2.50 + \$0 = \$2.50 $$.

:::
--- -->

## Cardinal Payoffs

Expected payoffs imply that payoffs are [cardinal]{.hi}

  * relative differences in payoffs matter
  * instead of *ordinal* where only rankings matter

::: {.incremental}
  * i.e. an outcome with payoff 2 is actually twice as good as an outcome with payoff 1.
:::

---

## Von-Neumann Morgenstern Utility

We need new assumptions for rationality over lotteries:

  * [Continuity:]{.hi} Small changes in probabilities shouldn't make your ranking jump around.

  * [Independence:]{.hi} If you know which of two lotteries you prefer, when I
  add a little bit of another unrelated option into both, it shouldn't change
  your mind.

  * *expected utility* requires special assumptions, so it gets it's own special name: 

    - [Von-Neumann Morgenstern utility function]{.hi}

---

## Types of Uncertainty
Two main types of uncertainty: [external]{.hi} and [internal]{.hi}.

::: {.incremental}
  * [External uncertainty]{.hi} from factors outside of the players' control
    - such as weather or other random events, or external players
  * [Internal uncertainty]{.hi} from players' own actions: 
    - when some player acts in an unpredictable way,
      - *even to themselves*
    - For example, I flip a coin to tell me what to choose
:::

<!-- ## External Uncertainty: States of Nature
* The simplest form of uncertainty that we'll discuss is <u>simple uncertainty</u> or uncertainty about the <u>state of nature</u>.
* Players don't know which state of nature will occur --- 
  but we assume that they do *know the probability associated with each state*.
---

## Example: A Card Game
There are two players, Doc and Wyatt. Both are dealt a hand of cards: there is
a 50\% probability that Wyatt's hand is better, and a 50\% probability that
Doc's is.  There are no ties.

* At the beginning of the game, both players must bet $1. 
* After seeing his cards, Doc may either Stay, keeping the $1 bet, or may Raise, bringing his bet to $2.
* Doc simultaneously decides to either Match Doc's bet, whatever that may be, or to Quit and forfeit his $1.
* If Wyatt Matches, the player with the better hand wins all the money. If Wyatt Quits, Doc wins all the money by default.
---

## Game Table: Doc's Hand is Better
In the state of nature where Doc has the better hand, this is the game table:

| Doc, Wyatt | $Match$ | $Quit$  |
|------------+---------+---------|
| $Stay$     | $1, -1$ | $1, -1$ |
| $Raise$    | $2, -2$ | $1,-1$  |

---

## Game Table: Wyatt's Hand is Better
On the other hand, if Wyatt has the better hand, this is the game table:

| Doc, Wyatt | $Match$ | $Quit$  |
|------------+---------+---------|
| $Stay$     | $-1, 1$ | $1, -1$ |
| $Raise$    | $-2, 2$ | $1,-1$  |

---

## Payoffs as Lotteries
We could solve each of these game tables separately 
but neither player knows which state really applies. 

* Instead, to solve this game, we must approach the payoffs as lotteries:

::: {.incremental}
* Doc's payoff from ($Stay,~Match$): gains 1 with probability 0.5, and loses 1 with probability 0.5.
* Wyatt's payoff from ($Stay,~Match$): loses 1 with probability 0.5, and gains 1 with probability 0.5.
* the expected payoffs of these lotteries are both 0. 
:::
---

## Game Table: Expected Payoffs

| Doc, Wyatt | $Match$            | $Quit$       |
|------------+--------------------+--------------|
| $Stay$     | <u>0</u>, <u>0</u> | <u>1</u>, -1 |
| $Raise$    | <u>0</u>, <u>0</u> | <u>1</u>,-1  |

::: {.incremental}
* The Nash equilibria under uncertainty are ($Stay,~Match$) and ($Raise,~Match$).
:::

---

## Variation: Unknown Probabilities
Suppose that the probability Doc has the better hand is $p$. 

  * How large does $p$ have to be before there is a Nash equilibrium where Wyatt Quits?
  
We can find the expected payoffs in terms of p:

::: {.incremental}
  * (Stay, Match):
    + Doc's Expected Payoff:
      - $1p - 1(1-p) = 2p - 1$
    + Wyatt's Expected Payoff:
      - $-1p + 1(1-p) = -2p + 1$
:::
---

## Variation: Unknown Probabilities

::::: {.columns}

:::: {.column}
(Raise, Match):

::: {.incremental}
  * Doc's Expected Payoff:
    - $2p - 2(1-p) = 4p -2$

  * Wyatt's Expected Payoff:
    - $-2p + 2(1-p) = -4p + 2$
:::
::::

:::: {.column}
(Stay, Quit) and (Raise, Quit):

::: {.incremental}
  * Doc's Expected Payoff:
    - $1p + 1(1-p) = 1$

  * Wyatt's Expected Payoff:
  - $-1p -1(1-p) = -1$
:::
::::
:::::

---

## Variation: Unknown Probabilities

| Doc, Wyatt | $Match$           | $Quit$  |
|------------+-------------------+---------|
| $Stay$     | $2p - 1, -2p + 1$ | $1, -1$ |
| $Raise$    | $4p - 2, -4p + 2$ | $1,-1$  |

If Wyatt Quits, Doc doesn't care whether he Stays or Raises 

To have a NE where Wyatt Quits, we just need Wyatt to be happy with Quitting.

::: {.incremental}
* ($Stay,~Quit$) is a NE if $-1 \geq -2p + 1$, i.e. if $p \geq 1$.
* ($Raise,~Quit$) is a NE if $-1 \geq -4p + 2$, i.e. if $p \geq \frac{3}{4}$.
* One interpretation of this is that it is only rational for Wyatt to Quit if he is very confident that Doc has the better hand.
:::
 -->
