## Thinking about Randomness

> "I, at any rate, am convinced that [God] does not throw dice"

  - Albert Einstein ^[1926, Letter to Max Born, published in 1971, Irene Born (translator), The Born-Einstein Letters, Walker and Company, New York]

---

## Thinking about Randomness

> "Rational decision makers are able to give reasons for each action they take; outside Las Vegas players do not spin roulette wheels"

  - Ariel Rubenstein
  ^[“John Nash: The Master of Economic Modeling.” The Scandinavian Journal of Economics 97, no. 1 (1995): 9–13. https://doi.org/10.2307/3440824.]

---

## Thinking about Randomness
  
Why should we use mixed strategies?!
  
::: {.incremental}
  
  * As we saw in Activity 2, 
  rarely do real life data fit in completely deterministic models

  * You can interpret the mixed strategy of one player as the beliefs of other players in equilibrium

  * Learning some basics of probability theory will help you outside of this class

:::

---

## Lotteries
::: {.incremental}
  * In this class, any choices with *uncertain* payoffs will be called [lotteries]{.hi}.
  * A lottery doesn't have to only be about money
  * For any set of outcomes in a lottery, there will be an associated
  probability: if $a$ is a possible outcome, then $P(a)$ is the probability
  that it occurs.
  
    + All probabilities must be between 0 and 1: $0 \leq P(a) \leq 1$ for all possibilities $a$.
    + Additionally, the probabilities given in a particular lottery must sum to
    exactly 1: we will assume that one, and exactly one, outcome must actually
    occur.
:::
---



## Expected Utility
::: {.incremental}
  * How can you know how much you like a given lottery
  if you don't even know what the outcome will be?

  * A natural way would be to think of how happy it would make you *on average*.

  * The economists' term for this idea is 
  [expected utility]{.hi} or [expected payoffs]{.hi}.

:::
---



## Expected Payoffs
  * You calculate an average by adding up the values of a lottery times the probability of how likely each is.

  $$U(a) = \mathbb{E}[u(a)] = \sum_{a}u(a)P(a)$$

::: {.incremental}
  * This is a weighted average of the payoffs associated with each outcome $a$, with the weights being the probabilities of each one happening.
:::
---

## Double or Nothing 'game'

![](figures/doubleornothing.png)

---

## Expected Payoff Examples

Zoidberg's expected payout if he Lets it Ride is 
$0.50(\$10) + 0.50(\$0) = \$5 - \$0 = \$5$.

::: {.incremental}
  * Let's face it, Zoidberg always has luck stacked against him, so suppose instead the coin has a 75\% probability of tails,

  * The expected payoff would then be 
  $$0.25(\$10) + 0.75(\$0) = \$2.50 + \$0 = \$2.50 $$.

:::
---

## Cardinal Payoffs

* Using expected payoffs implies that the payoffs of the outcomes are
[cardinal]{.hi}, not merely ordinal: this means that the payoffs can be used
not just to rank, but to compare the relative "goodness" of outcomes.

::: {.incremental}
  * i.e. an outcome with payoff 2 is actually twice as good as an outcome with payoff 1.
:::

---

## Von-Neumann Morgenstern Utility

There are a few other axioms beyond just *completeness* and *transitivity*
which are needed when it comes to making rational choices over lotteries.

::: {.incremental}

  * [Continuity:]{.hi} Small changes in lottery probabilities shouldn't make your ranking jump around.

  * [Independence:]{.hi} If you know which of two lotteries you prefer, when I
  add a little bit of another unrelated option into both, it shouldn't change
  your mind.

:::

Because *expected utility* requires special assumptions beyond those of regular *utility*, 
it gets it's own special name: 

[Von-Neumann Morgenstern utility function]{.hi}

---

## Types of Uncertainty
There are two main types of uncertainty that we'll cover in this course: [external]{.hi} and [internal]{.hi}.

::: {.incremental}
  * [External uncertainty]{.hi} results from factors outside of the game that the players don't control, such as weather or other random events.
  * [Internal uncertainty]{.hi} result from players' own actions inside of the game: it is caused whenever a player acts in a random way.
:::
---

## External Uncertainty: States of Nature
* The simplest form of uncertainty that we'll discuss is <u>simple uncertainty</u> or uncertainty about the <u>state of nature</u>.
* Players don't know which state of nature will occur --- 
  but we assume that they do *know the probability associated with each state*.
---

## Example: A Card Game
There are two players, Doc and Wyatt. Both are dealt a hand of cards: there is
a 50\% probability that Wyatt's hand is better, and a 50\% probability that
Doc's is.  There are no ties.

* At the beginning of the game, both players must bet $1. 
* After seeing his cards, Doc may either Stay, keeping the $1 bet, or may Raise, bringing his bet to $2.
* Doc simultaneously decides to either Match Doc's bet, whatever that may be, or to Quit and forfeit his $1.
* If Wyatt Matches, the player with the better hand wins all the money. If Wyatt Quits, Doc wins all the money by default.
---

## Game Table: Doc's Hand is Better
In the state of nature where Doc has the better hand, this is the game table:

| Doc, Wyatt | $Match$ | $Quit$  |
|------------+---------+---------|
| $Stay$     | $1, -1$ | $1, -1$ |
| $Raise$    | $2, -2$ | $1,-1$  |

---

## Game Table: Wyatt's Hand is Better
On the other hand, if Wyatt has the better hand, this is the game table:

| Doc, Wyatt | $Match$ | $Quit$  |
|------------+---------+---------|
| $Stay$     | $-1, 1$ | $1, -1$ |
| $Raise$    | $-2, 2$ | $1,-1$  |

---

## Payoffs as Lotteries
We could solve each of these game tables separately 
but neither player knows which state really applies. 

* Instead, to solve this game, we must approach the payoffs as lotteries:

::: {.incremental}
* Doc's payoff from ($Stay,~Match$): gains 1 with probability 0.5, and loses 1 with probability 0.5.
* Wyatt's payoff from ($Stay,~Match$): loses 1 with probability 0.5, and gains 1 with probability 0.5.
* the expected payoffs of these lotteries are both 0. 
:::
---

## Game Table: Expected Payoffs

| Doc, Wyatt | $Match$            | $Quit$       |
|------------+--------------------+--------------|
| $Stay$     | <u>0</u>, <u>0</u> | <u>1</u>, -1 |
| $Raise$    | <u>0</u>, <u>0</u> | <u>1</u>,-1  |

::: {.incremental}
* The Nash equilibria under uncertainty are ($Stay,~Match$) and ($Raise,~Match$).
:::

---

## Variation: Unknown Probabilities
Suppose that the probability Doc has the better hand is $p$. 

  * How large does $p$ have to be before there is a Nash equilibrium where Wyatt Quits?
  
::: {.incremental}
  * We can find the expected payoffs in terms of p:
  * (Stay, Match):
    + Doc's Expected Payoff:

    $1p - 1(1-p) = 2p - 1$

    + Wyatt's Expected Payoff:

    $-1p + 1(1-p) = -2p + 1$
:::
---



## Variation: Unknown Probabilities

::::: {.columns}

:::: {.column}
(Raise, Match):

::: {.incremental}
  * Doc's Expected Payoff:

  $2p - 2(1-p) = 4p -2$

  * Wyatt's Expected Payoff:

  $-2p + 2(1-p) = -4p + 2$
:::
::::

:::: {.column}
(Stay, Quit) and (Raise, Quit):

::: {.incremental}
  * Doc's Expected Payoff:

  $1p + 1(1-p) = 1$

  * Wyatt's Expected Payoff:

  $-1p -1(1-p) = -1$
:::
::::
:::::

---



## Variation: Unknown Probabilities

| Doc, Wyatt | $Match$           | $Quit$  |
|------------+-------------------+---------|
| $Stay$     | $2p - 1, -2p + 1$ | $1, -1$ |
| $Raise$    | $4p - 2, -4p + 2$ | $1,-1$  |

If Wyatt Quits, Doc doesn't care whether he Stays or Raises 

To have a NE where Wyatt Quits, we just need Wyatt to be happy with Quitting.

::: {.incremental}
* ($Stay,~Quit$) is a NE if $-1 \geq -2p + 1$, i.e. if $p \geq 1$.
* ($Raise,~Quit$) is a NE if $-1 \geq -4p + 2$, i.e. if $p \geq \frac{3}{4}$.
* One interpretation of this is that it is only rational for Wyatt to Quit if he is very confident that Doc has the better hand.
:::
---



## Variation: Sequential Moves

* It's not realistic to have Doc and Wyatt move at the same time: 
in actual card games, Doc would decide whether to raise, and Wyatt would then see that move and decide whether to match or quit.
* So let's model this as an extensive-form game and make a game tree:
---

## Sequential Card Game Tree
% \includegraphics[width=\textwidth]{Images/08SequentialCards.png}
---

## Information Sets in the Sequential Card Game
::: {.incremental}
* The dashed lines in this game tree denote information sets, showing that neither player knows the state of nature---however, Wyatt does know whether Doc chose to Stay or Raise.
* When Doc and Wyatt reach one of their information sets, they don't know which of its nodes they're actually at, but in this case, because the node is determined by the state of nature, they know the probabilities of each node.
* Once again, we can find the expected payoffs associated with each strategy profile. In fact, they're the same payoffs that we had in the strategic-form game---we just need to fit them into a game tree.
:::
---

## Expected Payoff Game Tree
% \begin{figure}
% \centering
% \includegraphics[width=\textwidth]{Images/08SequentialCardsVNM.png}
% \end{figure}
---

## SPNE in the Sequential-Move Card Game
Let's look for SPNEs in this game---they will depend on what p is.

  * A good place to start is with [indifference points]{.hi}; values of p that make the players indifferent between their choices. 

Let's look at Wyatt's decisions:

::: {.incremental}
  * In the left-hand subgame (after Doc Stays), Wyatt has the choice between $1 - 2p$ and $-1$. Indifference implies that $1 - 2p = -1$, or $p = 1$. Wyatt is only indifferent here if Doc is guaranteed to have the better hand; if $p < 1$, Wyatt will simply prefer to Match.
  * In the right-hand subgame (after Doc Raises), $2 - 4p = -1$ implies $p = \frac{3}{4}$. If $p < \frac{3}{4}$, Wyatt will prefer to Match; if $p > \frac{3}{4}$, Wyatt will prefer to Quit.
  * It may help to plot this on a number line...
:::
---

## SPNE in the Sequential-Move Card Game
Now let's consider Doc's decisions:

::: {.incremental}
  * If Wyatt plays (Match, Match), implying that $p \leq \frac{3}{4}$, Doc's choice is between $2p-1$ and $4p-2$. Doc is indifferent when $p = \frac{1}{2}$; when p is smaller, he prefers to Stay, and when p is larger, he prefers to Raise.
  * If Wyatt plays (Match, Quit), implying that $\frac{3}{4} \leq p \leq 1$, Doc's choice is between $2p - 1$ and $1$. Doc is indifferent if $p = 1$; for $\frac{3}{4} \leq p < 1$, Doc prefers to Raise.
  * If Wyatt plays (Quit, Quit), which he would only do if $p = 1$ exactly, Doc's choice is between $-1$ and $-1$: not really a choice at all. Doc is completely indifferent here.
:::
---

## Plotting SPNEs

---

## Summary of SPNE in Sequential-Move Card Game
We can summarize all of the possible SPNEs as follows:

::: {.incremental}
* \{Stay, (Match, Match)\} is an SPNE if $0 \leq p \leq \frac{1}{2}$.
* \{Raise, (Match, Match)\} is an SPNE if $\frac{1}{2} \leq p \leq \frac{3}{4}$.
* \{Raise, (Match, Quit)\} is an SPNE if $\frac{3}{4} \leq p \leq 1$.
* \{Stay, (Match, Quit)\}, \{Stay, (Quit, Quit)\}, and \{Raise, (Quit, Quit)\} are all SPNEs if $p = 1$.
:::
---

